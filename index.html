
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<!-- Meta tags for search engines to crawl -->
<meta name="robots" content="index,follow">
<meta name="keywords" content="Guangcong Wang; 王广聪; Computer Vision; Deep Learning; Sun Yat-set University, Nanyang Technological University; NTU">
<script src="assets/js/jquery.scrolly.min.js"></script>
<script src="assets/js/jquery.min.js"></script>
<link rel="author" href="https://wanggcong.github.io/">

    <title>Guangcong Wang - Homepage</title>
    <style>
@media screen and (max-device-width: 480px){
  body{
    -webkit-text-size-adjust: none;
  }
}
p { font-size : 16px; }
h1 { font-size : 34px; margin : 0; padding : 0; }
h2 { font-size : 20px; margin : 0; padding : 0; }
h3 { font-size : 18px; margin : 8; padding : 0; }
body { padding : 0; font-family : Arial; font-size : 16px; background-color : rgb(224, 224, 224); }
.title { width : 650px; margin : 20px auto; }
.container { width : 750px; margin : 20px auto; border-radius: 10px;  background-color : #fff; padding : 20px;  clear:both;}
.container_title { width : 750px; margin : 20px auto; border-radius: 10px;  padding : 20px;  clear:both;}
.iframe_video {float: left; margin-right: 30px}
#bio {
    padding-top : 20px;
}
#me { border : 0 solid black; margin-bottom : 50px; border-radius : 10px; }
#sidebar { margin-left : 25px; margin-right : 100px; border : 0 solid black; float : left; margin-bottom : 0;}
a { text-decoration : none; }
a:hover { text-decoration : underline; }
a, a:visited { color : #0050e7; }
.publogo { width: 100 px; margin-right : 20px; float : left; border : 0;}
.publication { clear : left; padding-bottom : 0px; }
.publication p { height : 100px; padding-top : 5px;}
.publication strong a { color : #0000A0; }
.publication .links { position : relative; top : 15px }
.publication .links a { margin-right : 20px; }
.codelogo { margin-right : 10px; float : left; border : 0;}
.code { clear : left; padding-bottom : 10px; vertical-align :middle;} 
.code .download a { display : block; margin : 0 15px; float : left;}
.code strong a { color : #000; }
.external a { margin : 0 10px; }
.external a.first { margin : 0 10px 0 0; }
	</style>
	<script async="" src="./homepage.js"></script>
</head>

<body>

    <div class="container">
        <h2>
            <a href="./index.html">Home</a>&nbsp;&nbsp;&nbsp;&middot;&nbsp;&nbsp;
            <a href="./competitions.html">Competitions</a>&nbsp;&nbsp;&nbsp;&middot;&nbsp;&nbsp;
            <a href="./publications.html">Publications</a>&nbsp;&nbsp;&middot;&nbsp;&nbsp;
            <a href="./datasets.html">Datasets</a>&nbsp;&nbsp;&middot;&nbsp;&nbsp;
            <a href="https://www.mmlab-ntu.com/">Team</a>&nbsp;&nbsp;&middot;&nbsp;&nbsp;
            <a href="https://github.com/wanggcong/">Github</a>&nbsp;&nbsp;&nbsp;&middot;&nbsp;&nbsp;
            <a href="https://scholar.google.com/citations?user=dk8EnkoAAAAJ&hl=en">Google Scholar</a>&nbsp;&nbsp;&nbsp;&middot;&nbsp;&nbsp;
            <a href="https://wanggrun.github.io/">Related Link</a>&nbsp;&nbsp;&nbsp;&middot;&nbsp;&nbsp;
            <a href="https://Wanggcong.github.io/index_chinese">中文版本</a><br>
        </h2>
    </div>

	<div class="container">
		<div id="sidebar">
            <img src="./wang3.jpg" vspace="10 px" width="180 px" id="me" itemprop="photo">
        </div>
		<div id="bio">

            <br>

			<h2>
				<span itemprop="name">Guangcong Wang <font size="4">王广聪</font> </span>
			</h2>

            <br>

			<p style="line-height:23px;">
				Research Fellow
                <br>
                School of Computer Science and Engineering
                <br>
                Nanyang Technological University
                <br>
                Email: wanggc3 at gmail.com or guangcong.wang at ntu.edu.sg
                <br>
                Address: ABN-02b-14, S-LAB, Nanyang Avenue  
                <br>
			</p>

            <br>

		</div>
	</div>

	<div class="container">
		<h2>Short Bio</h2>

        <p>Guangcong Wang is currently a research fellow in the <a href="http://scse.ntu.edu.sg">School of Computer Science and Engineering</a> at <a href="https://www.ntu.edu.sg/">Nanyang Technological University</a>, working with <a href="https://liuziwei7.github.io/">Prof. Ziwei Liu</a> and <a href="https://www.mmlab-ntu.com/person/ccloy/">Prof. Chen Change (Cavan) Loy</a>. Before that, he was a PhD student in the <a href="http://sdcs.sysu.edu.cn/">School of Computer Science</a> at <a href="http://www.sysu.edu.cn/en/index.htm">Sun Yat-set University</a>, supervised by <a href="http://sdcs.sysu.edu.cn/content/2498">Prof. Jianhuang Lai</a> and also co-supervised by <a href="http://sdcs.sysu.edu.cn/content/2478"> Prof. Xiaohua Xie</a>.</p>
        <p>His research interests include generative models, 3D, person re-identification, semi-supervised learning, interpretability of neural networks, and meta-learning. He has published some papers, such as TOG, IEEE T-NNLS, IEEE TIP, IEEE T-CSVT, ICCV, CVPR, ECCV, KDD, and AAAI.  </p>
        <p>He has served as a reviewer of IJCV, ICML, NeurIPS, ICCV, CVPR, ECCV, ICLR, AAAI, ICPR, IEEE TIP, IEEE T-CSVT, IEEE TOMM, Neurocomputing and IEEE Signal Processing Letters.</p>
        <p>He was awarded Excellent Doctoral Dissertation Award of <a href="http://www.cesexd.com/"> China Education Society of Electronics</a>. </p >
        <p>He joined <a href="https://www.mmlab-ntu.com/">MMLab@NTU</a>. He is also a member of <a href="https://wanggrun.github.io/projects/fast">FAST Lab</a>. </p>

	</div>
	
	<div class="container">
	<h2>Goals</h2>
		
	<p>His has two goals in this life. One is to build a plausible 3D virtual world system with machine learning methods, called Open 3D Virtual Reality (<a href="https://open3dvr.github.io/index.html">Open3DVR</a>). The other is to build a biotechnologial system with machine learning methods to solve biotechnologial problems in the future, called Open Biotechnology and Machine Learning (<a href="https://openbiotechml.github.io/index.html">OpenBiotechML</a>). </p>
	<p>Open3DVR and OpenBiotechML are non-profit open research platforms, which focus on advancing technologies and benefit humanity.</p>
	<p>Life is short. He will spend 30 years to develop related technologies to achieve these two goals. He will spend the first 10 years to develop Open3DVR (2023-2033) and spend the next 20 years (2033-2053) to develop OpenBiotechML. All relevant researchers are welcome.</p>
	<p><a href="https://open3dvr.github.io/index.html"><img src="./homepage_files/open3dvr_logo.png" style="width:200px;height:50px;"></a> &nbsp&nbsp&nbsp <a href="https://openbiotechml.github.io/index.html"><img src="./homepage_files/openbiotechml_logo.png" style="width:300px;height:50px;"></a></p>
</body>
	</div>


    <div class="container">
        <h2>News</h2>
	<p><font color='black'>[2022-08]</font> One TOG 2022 (Proc. SIGGRAPH Asia, journal-track) paper is accepted.</p> <!-- <font color='red'>NEW!</font> -->
	<p><font color='black'>[2022-07]</font> Two ECCV 2022 papers are accepted.</p> <!-- <font color='red'>NEW!</font> -->
        <p><font color='black'>[2021-07]</font> One ICCV 2021 paper (oral) is accepted.</p>
        <p><font color='black'>[2021-06]</font> One TIP paper is accepted.</p>
        <p><font color='black'>[2021-04]</font> I joined <a href="https://www.mmlab-ntu.com/">MMLab@NTU</a>. </p>
        <p><font color='black'>[2021-03]</font> One IEEE T-NNLS and one ICME (oral) are accepted.</p>
        <p><font color='black'>[2020-12]</font> I have received my PhD degree in Computer Science from Sun Yat-set University (<a href="https://mp.weixin.qq.com/s/D4F52P-ZXTloxoEXDkAV-g">Excellent Doctoral Dissertation Award of China Education Society of Electronics</a> and <a href="http://cse.sysu.edu.cn/content/6175">Excellent Doctoral Dissertation of SYSU</a>).</p> 
        <p><font color='black'>[2020-12]</font> Media Coverage: A large-scale person re-identification dataset named SYSU-30k is released, <a href="https://mp.weixin.qq.com/s/XsE0wBECzO6Mddtfdu8vVA">link</a>.<br></p>
    </div>

	
    <div class="container">    
    <h2>Academic Services (Reviewer)</h2>
    <h3>Conferences</h3>
    <li>ICLR: 2022, 2023 </li>
    <li>ICML: 2021, 2022, 2023 </li>
    <li>NeurIPS: 2020, 2021, 2022</li>    
    <li>ICCV: 2021, 2023 </li>
    <li>CVPR: 2021, 2022 </li>
    <li>ECCV: 2022 </li>
    <li>AAAI: 2020, 2021, 2022, 2023 </li>
    <li>ICPR: 2020, 2022 </li>
    <h3>Journals</h3>
    <li>IJCV </li>
    <li>IEEE TIP </li>
    <li>IEEE TOMM </li>
    <li>IEEE TCSVT </li>
    <li>Neurocomputing </li>
    <li>IEEE Signal Processing Letters </li>
    <li>The Visual Computer</li>
    <li>Image and Vison Computing</li>
    </div>


    <div class="container">
    <h2>Teaching and Co-supervision</h2>
    <li>Yinuo Yang, MSAI, NTU, Neural Perception and Reconstruction for Virtual Humans, 2021</li>
    <li>Liang Tong, FYP, NTU, Editing Anime Images using Generative Adversarial Network, 2021</li>
    <li>Long Zhuo, Intern, Sensetime, GAN compression, 2021</li>
    <li>Wenqi Liang, Master, SYSU, Unsupervised Single-modality and Cross-modality Person Re-identification, <a href="http://cse.sysu.edu.cn/content/6175">Excellent Master's Thesis</a>, 2021</li>
    <li>Enqi Zhang, Wenqi Liang (Outstanding Undergraduate's Thesis), Yang Zhou, Xu Li, Bingyun Liu etc., FYP, SYSU, 2016-2020.</li>   
    <li>Statistical Analysis Method, TA, 2018</li>
    <li>Signals and Systems, TA, 2018</li>
    <li>Digital Image Processing, TA, 2017</li>
    </div>

    <div class="container">
	<h2>Selected Publications</h2>
        <div class="publication">
            <img src="./homepage_files/scenedreamer_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://scene-dreamer.github.io/">SceneDreamer: Unbounded 3D Scene Generation from 2D Image Collections</a>
                </strong>
                <br>
                <br>
                Zhaoxi Chen, <b>Guangcong Wang</b>, Ziwei Liu.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2302.01330">PDF</a>
                    <a href="https://scene-dreamer.github.io/">Project Page</a>
                    <a href="https://github.com/Scene-Dreamer/SceneDreamer">Code</a>
                    <a href="https://www.youtube.com/watch?v=AjtOlDHsiyU">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
	    
        <div class="publication">
            <img src="./homepage_files/text2light_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://frozenburning.github.io/projects/text2light/">Text2Light: Zero-Shot Text-Driven HDR Panorama Generation</a>
                </strong>
                <br>
                <br>
                Zhaoxi Chen, <b>Guangcong Wang</b>, Ziwei Liu.
                <br>
                <em>ACM Transactions on Graphics (SIGGRAPH Asia), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2209.09898">PDF</a>
                    <a href="https://frozenburning.github.io/projects/text2light/">Project Page</a>
                    <a href="https://github.com/FrozenBurning/Text2Light">Code</a>
                    <a href="https://www.youtube.com/watch?v=XDx6tOHigPE">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
	<br>
         <div class="publication">
            <img src="./homepage_files/stylelight_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://style-light.github.io/">StyleLight: HDR Panorama Generation for Lighting Estimation and Editing</a>
                </strong>
                <br>
                <br>
                <b>Guangcong Wang</b>, Yinuo Yang, Chen Change Loy, Ziwei Liu.
                <br>
                <em>European Conference on Computer Vision (ECCV), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2207.14811">PDF</a>
                    <a href="https://style-light.github.io/">Project Page</a>
                    <a href="https://github.com/Wanggcong/StyleLight">Code</a>
                    <a href="https://www.youtube.com/watch?v=sHeWK1MSPg4">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
	         

        <div class="publication">
            <img src="./homepage_files/fastvid2vid_logo.gif" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://fast-vid2vid.github.io/">Fast-Vid2Vid: Spatial-Temporal Compression for Video-to-Video Synthesis</a>
                </strong>
                <br>
                <br>
                Long Zhuo, <b>Guangcong Wang</b>, Shikai Li, Wayne Wu, Ziwei Liu.
                <br>
                <em>European Conference on Computer Vision (ECCV), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2207.05049">PDF</a>
                    <a href="https://fast-vid2vid.github.io/">Project Page</a>
                    <a href="https://github.com/fast-vid2vid/fast-vid2vid">Code</a>
                    <a href="https://www.youtube.com/watch?v=AhEqjGVuk4A">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br> 
        
        <div class="publication">
            <img src="./homepage_files/triplet_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://github.com/wanggrun/triplet">Solving Inefficiency of Self-supervised Representation Learning</a>
                </strong>
                <br>
                <br>
                Guangrun Wang, Keze Wang, <b>Guangcong Wang</b>, Philip Torr, Liang Lin.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_Solving_Inefficiency_of_Self-Supervised_Representation_Learning_ICCV_2021_paper.pdf">PDF</a>
                    <a href="https://github.com/wanggrun/triplet">Code</a>
                    <a href="https://arxiv.org/abs/2104.08760">arXiv</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br> 

        <div class="publication">
            <img src="./homepage_files/h2h_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://ieeexplore.ieee.org/document/9470916">Homogeneous-to-Heterogeneous:  Unsupervised Learning for  RGB-Infrared Person Re-Identification</a>
                </strong>
                <br>
                <br>
                Wenqi Liang, <b>Guangcong Wang</b>, Jianhuang Lai, Xiaohua Xie.
                <br>
                <em>IEEE Transactions on Image Processing (TIP), 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://ieeexplore.ieee.org/document/9470916">PDF</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br> 

        <div class="publication">
            <img src="./homepage_files/Joint Learning_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://ieeexplore.ieee.org/document/9408408">Joint Learning of Neural Transfer and Architecture Adaptation for Image Recognition</a>
                </strong>
                <br>
                <br>
                Guangrun Wang, Liang Lin, Rongcong Chen, <b>Guangcong Wang</b>, Jiqi Zhang.
                <br>
                <em>IEEE Transactions on Neural Networks and Learning Systems (TNNLS), 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://ieeexplore.ieee.org/document/9408408">PDF</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>         

        <div class="publication">
            <img src="./homepage_files/Confidence_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2105.06714">Confidence-Guided Adaptive Gate and Dual Differential Enhancement for Video Salient Object Detection</a>
                </strong>
                <br>
                <br>
                Peijia Chen, Jianhuang Lai, <b>Guangcong Wang</b>, Xiaohua Xie.
                <br>
                <em>IEEE International Conference on Multimedia and Expo (ICME), 2021 (oral)</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2105.06714">PDF</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br> 

        <div class="publication">
            <img src="./homepage_files/Smoothing_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Smoothing_Adversarial_Domain_Attack_and_P-Memory_Reconsolidation_for_Cross-Domain_Person_CVPR_2020_paper.pdf">Smoothing Adversarial Domain Attack and p-Memory Reconsolidation for Cross-Domain Person Re-Identification</a>
                </strong>
                <br>
                <br>
                <b>Guangcong Wang</b>, Jianhuang Lai, Wenqi Liang, Guangrun Wang.
                <br>
                <em>Computer Vision and Pattern Recognition Conference (CVPR) , 2020</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Smoothing_Adversarial_Domain_Attack_and_P-Memory_Reconsolidation_for_Cross-Domain_Person_CVPR_2020_paper.pdf">PDF</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>         
    
        <div class="publication">
            <img src="./homepage_files/weaklyreid_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://github.com/wanggrun/SYSU-30k">Weakly Supervised Person Re-identification: Cost-effective Learning with A New Benchmark</a>
                </strong>
                <br>
                <br>
                Guangrun Wang, <b>Guangcong Wang</b>, Xujie Zhang, Jianhuang Lai, Liang Lin.
                <br>
                <em>IEEE Transactions on Neural Networks and Learning Systems (TNNLS), 2020</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/1904.03845">PDF</a>
                    <a href="https://github.com/wanggrun/SYSU-30k">Dataset, Code, Pretrained model</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br> 


        <div class="publication">
            <img src="./homepage_files/treeconv_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://www.kdd.org/kdd2020/accepted-papers/view/grammatically-recognizing-images-with-tree-convolution">Grammatically Recognizing Images with Tree Convolution</a>
                </strong>
                <br>
                <br>
                Guangrun Wang, <b>Guangcong Wang</b>, Keze Wang, Xiaodan Liang, Liang Lin.
                <br>
                <em>ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (KDD), 2020</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://www.kdd.org/kdd2020/accepted-papers/view/grammatically-recognizing-images-with-tree-convolution">PDF</a>
                    <a href="https://github.com/wanggrun/TreeConv/stargazers">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>   

        <div class="publication">
            <img src="./homepage_files/streid_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://github.com/Wanggcong/Spatial-Temporal-Re-identification">Spatial-Temporal Person Re-identification</a>
                </strong>
                <br>
                <br>
                <b>Guangcong Wang</b>, Jianhuang Lai, Peigen Huang and Xiaohua Xie.
                <br>
                <em>The Association for the Advancement of Artificial Intelligence (AAAI), 2019</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://wvvw.aaai.org/ojs/index.php/AAAI/article/view/4921">PDF</a>
                    <a href="https://github.com/Wanggcong/Spatial-Temporal-Re-identification">Code</a>
                    <a href="https://arxiv.org/abs/1812.03282">arXiv</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br> 

      

        <div class="publication">
            <img src="./homepage_files/m2m_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/pdf/1811.03768.pdf">M2M-GAN: Many-to-Many Generative Adversarial Transfer Learning for Person Re-Identification</a>
                </strong>
                <br>
                <br>
                Wenqi Liang, <b>Guangcong Wang</b>, Jianhuang Lai.
                <br>
                <em>ACTA AUTOMATICA SINICA, 2019</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/pdf/1811.03768.pdf">arXiv</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br> 
        <div class="publication">
            <img src="./homepage_files/P2SNet_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://ieeexplore.ieee.org/document/8025424">P2SNet: Can an Image Match a Video for Person Re-identification in an End-to-end Way</a>
                </strong>
                <br>
                <br>
                <b>Guangcong Wang</b>, Jianhuang Lai, Xiaohua Xie.
                <br>
                <em>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2018</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://ieeexplore.ieee.org/document/8025424">PDF</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>         

        <div class="publication">
            <img src="./homepage_files/DGL_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Wang_Deep_Growing_Learning_ICCV_2017_paper.pdf">Deep Growing Learning</a>
                </strong>
                <br>
                <br>
                <b>Guangcong Wang</b>, Xiaohua Xie, Jianhuang Lai, Jiaxuan Zhuo.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2017</em>
                <br>
                <br>
                <span class="links">
                    <a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Wang_Deep_Growing_Learning_ICCV_2017_paper.pdf">PDF</a>
                    <a href="https://github.com/Wanggcong/Deep-growing-learning">Code</a>
                    
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>         
         
        <div style="text-align:right">
            Website template credits to <a href="https://liuziwei7.github.io/">Ziwei Liu</a>
        </div>
	</div>	

       

</body></html>
