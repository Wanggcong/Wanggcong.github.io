
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<!-- Meta tags for search engines to crawl -->
<meta name="robots" content="index,follow">
<meta name="keywords" content="Guangcong Wang; 王广聪; Computer Vision; Deep Learning; Sun Yat-set University, Nanyang Technological University; NTU">
<script src="assets/js/jquery.scrolly.min.js"></script>
<script src="assets/js/jquery.min.js"></script>
<link rel="author" href="https://wanggcong.github.io/">

    <title>Guangcong Wang - Homepage</title>
    <style>
@media screen and (max-device-width: 480px){
  body{
    -webkit-text-size-adjust: none;
  }
}
p { font-size : 16px; }
h1 { font-size : 34px; margin : 0; padding : 0; }
h2 { font-size : 20px; margin : 0; padding : 0; }
h3 { font-size : 18px; margin : 8; padding : 0; }
body { padding : 0; font-family : Arial; font-size : 16px; background-color : rgb(224, 224, 224); }
.title { width : 650px; margin : 20px auto; }
.container { width : 750px; margin : 20px auto; border-radius: 10px;  background-color : #fff; padding : 20px;  clear:both;}
.container_title { width : 750px; margin : 20px auto; border-radius: 10px;  padding : 20px;  clear:both;}
.iframe_video {float: left; margin-right: 30px}
#bio {
    padding-top : 20px;
}
#me { border : 0 solid black; margin-bottom : 50px; border-radius : 10px; }
#sidebar { margin-left : 25px; margin-right : 100px; border : 0 solid black; float : left; margin-bottom : 0;}
a { text-decoration : none; }
a:hover { text-decoration : underline; }
a, a:visited { color : #0050e7; }
.publogo { width: 100 px; margin-right : 20px; float : left; border : 0;}
.publication { clear : left; padding-bottom : 0px; }
.publication p { height : 100px; padding-top : 5px;}
.publication strong a { color : #0000A0; }
.publication .links { position : relative; top : 15px }
.publication .links a { margin-right : 20px; }
.codelogo { margin-right : 10px; float : left; border : 0;}
.code { clear : left; padding-bottom : 10px; vertical-align :middle;} 
.code .download a { display : block; margin : 0 15px; float : left;}
.code strong a { color : #000; }
.external a { margin : 0 10px; }
.external a.first { margin : 0 10px 0 0; }
    </style>
    <script async="" src="./homepage.js"></script>
</head>

<body>

    <div class="container">
        <h2>
            <a href="./index.html">Return 返回</a><br>
        </h2>
    </div>



    <div class="container">
    <h2>Publications and preprints</h2> 
    
    <h4>2022</h4> 
    -  <b>Guangcong Wang</b>, Yinuo Yang, Chen Change Loy, and Ziwei Liu. StyleLight: HDR Panorama Generation for Lighting Estimation and Editing, <b>ECCV</b> 2022, <a href="https://arxiv.org/abs/2207.14811">paper</a>, <a href="https://style-light.github.io/">project</a>,<a href="https://github.com/Wanggcong/StyleLight">code</a>. <br>
    - Long Zhuo,  <b>Guangcong Wang</b>, Shikai Li, Wayne Wu, and Ziwei Liu. Fast-Vid2Vid: Spatial-Temporal Compression for Video-to-Video Synthesis, <b>ECCV</b> 2022, <a href="https://arxiv.org/abs/2207.05049.pdf">paper</a>, <a href="https://fast-vid2vid.github.io/">project</a>,<a href="https://github.com/fast-vid2vid/fast-vid2vid">code</a>. <br>
    <h4>2021</h4> 
    - Guangrun Wang, Keze Wang, <b>Guangcong Wang</b>, Philip Torr and Liang Lin. Solving Inefficiency of Self-supervised Representation Learning. <b>ICCV</b> 2021 (oral), <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_Solving_Inefficiency_of_Self-Supervised_Representation_Learning_ICCV_2021_paper.pdf">paper</a>, <a href="https://arxiv.org/abs/2104.08760">arXiv</a>,<a href="https://github.com/wanggrun/triplet">code</a>. <br>
    - Wenqi Liang, <b>Guangcong Wang</b>, Jianhuang Lai, and Xiaohua Xie. Homogeneous-to-Heterogeneous:  Unsupervised Learning for  RGB-Infrared Person Re-Identification, <b>TIP</b> (accepted), 2021, <a href="https://ieeexplore.ieee.org/document/9470916">paper</a>.<br>
    - Guangrun Wang, Liang Lin, Rongcong Chen, <b>Guangcong Wang</b>, Jiqi Zhang, Joint Learning of Neural Transfer and Architecture Adaptation for Image Recognition. <b>TNNLS</b> (accepted), 2021, <a href="https://ieeexplore.ieee.org/document/9408408">paper</a>. <br>
    - Peijia Chen, Jianhuang Lai, <b>Guangcong Wang</b>, and Xiaohua Xie. Confidence-Guided Adaptive Gate and Dual Differential Enhancement for Video Salient Object Detection, <b>ICME</b> 2021 (oral), <a href="https://arxiv.org/abs/2105.06714">paper</a>. <br>
    <h4>2020</h4> 
    - <b>Guangcong Wang</b>, Jianhuang Lai, Wenqi Liang and Guangrun Wang. Smoothing Adversarial Domain Attack and p-Memory Reconsolidation for Cross-Domain Person Re-Identification，<b>CVPR</b>, 2020, <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Smoothing_Adversarial_Domain_Attack_and_P-Memory_Reconsolidation_for_Cross-Domain_Person_CVPR_2020_paper.pdf">paper</a>.<br>
    - Guangrun Wang, <b>Guangcong Wang</b>, Xujie Zhang, Jianhuang Lai, and Liang Lin Weakly Supervised Person Re-ID: Differentiable Graphical Learning and A New Benchmark [J]. IEEE Transactions on Neural Networks and Learning Systems (<b>T-NNLS</b>, accepted), 2020, <a href="https://arxiv.org/abs/1904.03845">paper</a>, <a href="https://github.com/wanggrun/SYSU-30k">dataset and code</a>, <a href="https://github.com/Wanggcong/Wanggcong.github.io/blob/master/cites/weak.txt">bibtex</a>.<br>
    - Guangrun Wang, <b>Guangcong Wang</b>, Keze Wang, Xiaodan Liang, Liang Lin, Grammatically Recognizing Images with Tree Convolution [C]. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (<b>KDD</b>), San Diego, CA, USA, August 4-8, 2020. ACM, 2020, <a href="https://www.kdd.org/kdd2020/accepted-papers/view/grammatically-recognizing-images-with-tree-convolution">paper</a>, <a href="https://github.com/wanggrun/TreeConv/stargazers">code</a>.<br>

    <h4>2019</h4> 
    - <b>Guangcong Wang</b>, Jianhuang Lai, Peigen Huang and Xiaohua Xie. Spatial-Temporal Person Re-identification. <b>AAAI</b>, 2019 (16.2% accepted rate, I ranked 1st in the Market-1501 and DukeMTMC-reID leaderboards for months). <a href="https://wvvw.aaai.org/ojs/index.php/AAAI/article/view/4921">paper</a>, <a href="https://github.com/Wanggcong/Spatial-Temporal-Re-identification">code</a>, <a href="https://github.com/Wanggcong/Wanggcong.github.io/blob/master/cites/st_reid.txt">bibtex</a>.<br>
    - <b>Guangcong Wang</b>, Jianhuang Lai, Guangrun Wang, Wenqi Liang, Function Feature Learning of Neural Networks, 2019.<br>
    - Rongcong Chen, Liang Lin, Guangrun Wang, <b>Guangcong Wang</b>, Jiqi Zhang, Image Recognition Model and Method with Network Structure Self-Adjusting [Patent]. Published number: 111062465A, 2020.04.24<br>

    - <b>Guangcong Wang</b>, Jianhuang Lai, Wenqi Liang, and Guangrun Wang. Learnable Parameter Similarity, <b>arxiv</b>, 2019, <a href="hhttps://arxiv.org/abs/1907.11943">paper</a>, <a href="https://github.com/Wanggcong/learnable-parameter-similarity">code</a>, <a href="hhttps://github.com/Wanggcong/Wanggcong.github.io/blob/master/cites/lps.txt">bibtex</a>. <br>
    - Wenqi Liang, <b>Guangcong Wang</b>, and Jianhuang Lai. Asymmetric Cross-domain Transfer Learning of Person Re-identification Based on the Many-to-Many Generative Adversarial Network, <b>ACTA AUTOMATICA SINICA</b>, 2019.<br>
    - Guangrun Wang, <b>Guangcong Wang</b>, Xujie Zhang, Jianhuang Lai, and Liang Lin. Weakly Supervised Person Re-identification: Cost-effective Learning with A New Benchmark, <b>arxiv</b>, 2019. <a href="https://arxiv.org/abs/1904.03845">paper</a>, <a href="https://github.com/wanggrun/SYSU-30k">dataset</a>, <a href="https://github.com/Wanggcong/Wanggcong.github.io/blob/master/cites/weak.txt">bibtex</a>.<br>
    - <b>Guangcong Wang</b>, Jianhuang Lai, Zhenyu Xie and Xiaohua Xie. Discovering Underlying Person Structure Pattern with Relative Local Distance for Person Re-identification, <b>arxiv</b>, 2019. <a href="https://arxiv.org/abs/1901.10100">paper</a>, <a href="https://github.com/Wanggcong/RLD_codes">code</a>, <a href="https://github.com/Wanggcong/Wanggcong.github.io/blob/master/cites/rld.txt">bibtex</a>.<br>


    <h4>2018</h4> 
    - <b>Guangcong Wang</b>, Jianhuang Lai and Xiaohua Xie. P2SNet: Can an Image Match a Video for Person Re-identification in an End-to-end Way? <b>T-CSVT</b>, 2018. <a href="https://github.com/Wanggcong/Wanggcong.github.io/blob/master/papers/P2SNet.pdf">paper</a>, <a href="https://github.com/Wanggcong/Wanggcong.github.io/blob/master/cites/p2snet.txt">bibtex</a><br>
    - Jiaxuan Zhuo, Zeyu Chen, Jianhuang Lai and <b>Guangcong Wang</b>. Occluded Person Re-identification. <b>ICME</b>, 2018. <a href="https://arxiv.org/abs/1804.02792">paper</a>, <a href="https://github.com/tinajia2012/ICME2018_Occluded-Person-Reidentification_datasets">dataset</a>, <a href="https://github.com/Wanggcong/Wanggcong.github.io/blob/master/cites/opr.txt">bibtex</a>.<br>
    - Jianhuang Lai, Peigen Huang, <b>Guangcong Wang</b>, Xiaohua Xie. Two stream based Spatial-Temporal Person Re-identification [Patent]. Published number: CN109325471A, 2018.10.31<br>
    - Wenqi Liang, <b>Guangcong Wang</b>, Jianhuang Lai, and Junyong Zhu. M2M-GAN: Many-to-Many Generative Adversarial Transfer Learning for Person Re-Identification. <b>arxiv</b>, 2018. <a href="https://arxiv.org/pdf/1811.03768.pdf">paper</a>, <a href="https://github.com/Wanggcong/Wanggcong.github.io/blob/master/cites/m2m.txt">bibtex</a>.<br>


    <h4>2017</h4> 
    - <b>Guangcong Wang</b>, Xiaohua Xie, Jianhuang Lai and Jiaxuan Zhuo. Deep Growing Learning. <b>ICCV</b>, 2017. <a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Wang_Deep_Growing_Learning_ICCV_2017_paper.pdf">paper</a>, <a href="https://github.com/Wanggcong/Deep-growing-learning">code</a>, <a href="https://github.com/Wanggcong/Wanggcong.github.io/blob/master/cites/dgl.txt">bibtex</a><br>
    - Jianhuang Lai, Xiao wang, <b>Guangcong Wang</b>, Multiple Object Tracking based Deep Learning and Conditional Random Field [Patent]. Published number: CN107122735A, 2017.09.01<br>

    </div>

</body></html>
