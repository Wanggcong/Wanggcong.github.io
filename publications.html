
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<!-- Meta tags for search engines to crawl -->
<meta name="robots" content="index,follow">
<meta name="keywords" content="Guangcong Wang; 王广聪; Computer Vision; Deep Learning; Sun Yat-set University, Nanyang Technological University; NTU">
<script src="assets/js/jquery.scrolly.min.js"></script>
<script src="assets/js/jquery.min.js"></script>
<link rel="author" href="https://wanggcong.github.io/">

    <title>Guangcong Wang - Homepage</title>
    <style>
@media screen and (max-device-width: 480px){
  body{
    -webkit-text-size-adjust: none;
  }
}
p { font-size : 16px; }
h1 { font-size : 34px; margin : 0; padding : 0; }
h2 { font-size : 20px; margin : 0; padding : 0; }
h3 { font-size : 18px; margin : 8; padding : 0; }
body { padding : 0; font-family : Arial; font-size : 16px; background-color : rgb(224, 224, 224); }
.title { width : 650px; margin : 20px auto; }
.container { width : 750px; margin : 20px auto; border-radius: 10px;  background-color : #fff; padding : 20px;  clear:both;}
.container_title { width : 750px; margin : 20px auto; border-radius: 10px;  padding : 20px;  clear:both;}
.iframe_video {float: left; margin-right: 30px}
#bio {
    padding-top : 20px;
}
#me { border : 0 solid black; margin-bottom : 50px; border-radius : 10px; }
#sidebar { margin-left : 25px; margin-right : 100px; border : 0 solid black; float : left; margin-bottom : 0;}
a { text-decoration : none; }
a:hover { text-decoration : underline; }
a, a:visited { color : #0050e7; }
.publogo { width: 100 px; margin-right : 20px; float : left; border : 0;}
.publogo2 { width: 100 px; margin-right : 20px; float : left; border : 0; padding-bottom : 10px;}
.publogo3 { width: 100 px; margin-right : 20px; float : left; border : 0; padding-bottom : 20px;}
.publogo4 { width: 100 px; margin-right : 20px; float : left; border : 0; padding-bottom : 35px;}
.publication { clear : left; padding-bottom : 0px; }
.publication p { height : 100px; padding-top : 5px;}
.publication strong a { color : #0000A0; }
.publication .links { position : relative; top : 15px }
.publication .links a { margin-right : 20px; }
.codelogo { margin-right : 10px; float : left; border : 0;}
.code { clear : left; padding-bottom : 10px; vertical-align :middle;} 
.code .download a { display : block; margin : 0 15px; float : left;}
.code strong a { color : #000; }
.external a { margin : 0 10px; }
.external a.first { margin : 0 10px 0 0; }
    </style>
    <script async="" src="./homepage.js"></script>
</head>

<body>

    <div class="container">
        <h2>
            <a href="./index.html">Return 返回</a><br>
        </h2>
    </div>


    

  <div class="container">
	<h2> Publications and Pre-prints</h2> 
    <p>*共同一作，+同等通讯作者</p>
    <div class="publication">
        <img style=”float: left; padding: 0px 0px 30px 0px;” src="./homepage_files/Style4D_logo.png" class="publogo2" width="200 px">
        <p> 
            <strong>
                <a href="https://becky-catherine.github.io/Style4D/">ObjFiller-3D: Consistent Multi-view 3D Inpainting via Video Diffusion Models</a>
            </strong>
            <br>
            Beiqi Chen*, Shuai Shao*, Haitang Feng, Jianhuang Lai, Jianlou Si+, <b>Guangcong Wang</b>+
            <br>
            <em>Arxiv, 2025</em>
            <br>
            <span class="links">
                <a href="https://arxiv.org/abs/2508.19243">PDF</a>
                <a href="https://becky-catherine.github.io/Style4D/">Project Page</a>
                <a href="https://github.com/Becky-catherine/Style4D-Bench">Code</a> 
                <a href="https://www.youtube.com/watch?v=Tf6QnksXFxQ">Demo</a>
            </span>
        </p>
    </div>
    <br>
    <br>
    <br>   

    <div class="publication">
        <img style=”float: left; padding: 0px 0px 30px 0px;” src="./homepage_files/Style4D_logo.png" class="publogo2" width="200 px">
        <p> 
            <strong>
                <a href="https://becky-catherine.github.io/Style4D/">ObjFiller-3D: Consistent Multi-view 3D Inpainting via Video Diffusion Models</a>
            </strong>
            <br>
            Beiqi Chen*, Shuai Shao*, Haitang Feng, Jianhuang Lai, Jianlou Si+, <b>Guangcong Wang</b>+
            <br>
            <em>Arxiv, 2025</em>
            <br>
            <span class="links">
                <a href="https://arxiv.org/abs/2508.19243">PDF</a>
                <a href="https://becky-catherine.github.io/Style4D/">Project Page</a>
                <a href="https://github.com/Becky-catherine/Style4D-Bench">Code</a> 
                <a href="https://www.youtube.com/watch?v=Tf6QnksXFxQ">Demo</a>
            </span>
        </p>
    </div>
    <br>
    <br>
    <br>     
    
    <div class="publication">
        <img style=”float: left; padding: 0px 0px 30px 0px;” src="./homepage_files/objfiller3D_logo.png" class="publogo2" width="200 px">
        <p> 
            <strong>
                <a href="https://objfiller3d.github.io/">ObjFiller-3D: Consistent Multi-view 3D Inpainting via Video Diffusion Models</a>
            </strong>
            <br>
            Haitang Feng, Jie Liu, Jie Tang+, Gangshan Wu, Beiqi Chen, Jianhuang Lai, <b>Guangcong Wang</b>+
            <br>
            <em>Arxiv, 2025</em>
            <br>
            <span class="links">
                <a href="https://arxiv.org/abs/2508.18271">PDF</a>
                <a href="https://objfiller3d.github.io/">Project Page</a>
                <a href="https://github.com/objfiller3d/ObjFiller-3D">Code</a> 
                <a href="https://www.youtube.com/watch?v=0YZoKtpvqHY">Demo</a>
            </span>
        </p>
    </div>
    <br>
    <br>
    <br>     


    <div class="publication">
        <img style=”float: left; padding: 0px 0px 30px 0px;” src="./homepage_files/Distilled_3DGS_logo.png" class="publogo2" width="200 px">
        <p> 
            <strong>
                <a href="https://distilled3dgs.github.io/">Distilled-3DGS: Distilled 3D Gaussian Splatting</a>
            </strong>
            <br>
            Lintao Xiang<sup>*</sup>, Xinkai Chen<sup>*</sup>, Jianhuang Lai, <b>Guangcong Wang</b>.
            <br>
            <em>Arxiv, 2025</em>
            <br>
            <span class="links">
                <a href="https://arxiv.org/abs/2508.14037">PDF</a>
                <a href="https://distilled3dgs.github.io/">Project Page</a>
                <a href="https://github.com/lt-xiang/Distilled-3DGS">Code</a> 
                <a href="https://distilled3dgs.github.io/">Demo</a>
            </span>
        </p>
    </div>
    <br>
    <br>
    <br>  

    <div class="publication">
        <img style=”float: left; padding: 0px 0px 30px 0px;” src="./homepage_files/free4D_logo.gif" class="publogo2" width="200 px">
        <p> 
            <strong>
                <a href="https://free4d.github.io/">Free4D: Tuning-free 4D Scene Generation with Spatial-Temporal Consistency</a>
            </strong>
            <br>
            Tianqi Liu<sup>*</sup>, Zihao Huang<sup>*</sup>, Zhaoxi Chen, <b>Guangcong Wang</b>, Shoukang Hu, Liao Shen, Huiqiang Sun, Zhiguo Cao, Wei Li<sup>+</sup>, Ziwei Liu<sup>+</sup>.
            <br>
            <em>International Conference on Computer Vision (ICCV), 2025</em>
            <br>
            <span class="links">
                <a href="https://arxiv.org/abs/2503.20785">PDF</a>
                <a href="https://free4d.github.io/">Project Page</a>
                <a href="https://github.com/TQTQliu/Free4D">Code</a> 
                <a href="https://www.youtube.com/watch?v=GpHnoSczlhA&feature=youtu.be">Demo</a>
            </span>
        </p>
    </div>
    <br>
    <br>
    <br>


    <div class="publication">
        <img style=”float: left; padding: 0px 0px 30px 0px;” src="./homepage_files/SegmentDreamer_logo.gif" class="publogo2" width="200 px">
        <p> 
            <strong>
                <a href="https://zjhjojo.github.io/segmentdreamer/">SegmentDreamer: Towards High-fidelity Text-to-3D Synthesis with Segmented Consistency Trajectory Distillationy</a>
            </strong>
            <br>
            Jiahao Zhu, Zixuan Chen, <b>Guangcong Wang</b>, Xiaohua Xie, Yi Zhou.
            <br>
            <em>International Conference on Computer Vision (ICCV), 2025</em>
            <br>
            <span class="links">
                <a href="https://arxiv.org/pdf/2507.05256v1">PDF</a>
                <a href="https://zjhjojo.github.io/segmentdreamer/">Project Page</a>
                <a href="https://github.com/zjhJOJO/SegmentDreamer">Code</a> 
                <a href="https://www.youtube.com/watch?v=haUjuRgiis0">Demo</a>
            </span>
        </p>
    </div>
    <br>
    <br>
    <br>


    <div class="publication">
        <img style=”float: left; padding: 0px 0px 30px 0px;” src="./homepage_files/DiffV2IR_logo.gif" class="publogo2" width="200 px">
        <p> 
            <strong>
                <a href="https://diffv2ir.github.io/">DiffV2IR: Visible-to-Infrared Diffusion Model via Vision-Language Understanding</a>
            </strong>
            <br>
            Linyan Ran, Lidong Wang, <b>Guangcong Wang</b>, Peng Wang, Yangning Zhang.
            <br>
            <em>Arxiv, 2025</em>
            <br>
            <span class="links">
                <a href="https://arxiv.org/abs/2503.19012">PDF</a>
                <a href="https://diffv2ir.github.io/">Project Page</a>
                <a href="https://github.com/LidongWang-26/DiffV2IR">Code</a> 
                <a href="https://www.youtube.com/watch?v=YbUuvjnfejE&feature=youtu.be">Demo</a>
            </span>
        </p>
    </div>
    <br>
    <br>
    <br>

    <div class="publication">
        <img style=”float: left; padding: 0px 0px 30px 0px;” src="./homepage_files/HLV-1K_logo.png" class="publogo2" width="200 px">
        <p> 
            <strong>
                <a href="https://arxiv.org/abs/2501.01645">HLV-1K: A Large-scale Hour-Long Video Benchmark for Time-Specific Long Video Understanding</a>
            </strong>
            <br>
            Heqing Zou, Tianze Luo, Guiyang Xie, Victor (Xiao Jie)Zhang, Fengmao Lv, <b>Guangcong Wang</b>, Junyang Chen, Zhuochen Wang, Hansheng Zhang, Huaijian Zhang
            <br>
            <em>IEEE International Conference on Multimedia and Expo (ICME), 2025</em>
            <br>
            <span class="links">
                <a href="https://arxiv.org/abs/2501.01645">PDF</a>
                <!-- <a href="https://diffv2ir.github.io/">Project Page</a> -->
                <!-- <a href="https://github.com/LidongWang-26/DiffV2IR">Code</a>  -->
                <!-- <a href="https://www.youtube.com/watch?v=YbUuvjnfejE&feature=youtu.be">Demo</a> -->
            </span>
        </p>
    </div>
    <br>
    <br>
    <br>


    <div class="publication">
        <img style=”float: left; padding: 0px 0px 30px 0px;” src="./homepage_files/wildavatar_logo.png" class="publogo2" width="200 px">
        <p> 
            <strong>
                <a href="https://wildavatar.github.io/">WildAvatar: Web-scale In-the-wild Video Dataset for 3D Avatar Creation</a>
            </strong>
            <br>
            Zihao Huang, Shoukang Hu, <b>Guangcong Wang</b>, Tianqi Liu, Yuhang Zang, Zhiguo Cao, Wei Li, Ziwei Liu.
            <br>
            <em>Computer Vision and Pattern Recognition Conference (CVPR), 2025</em>
            <br>
            <span class="links">
                <a href="https://arxiv.org/pdf/2407.02165v2">PDF</a>
                <a href="https://wildavatar.github.io/">Project Page</a>
                <a href="https://github.com/wildavatar/WildAvatar_Toolbox">Code</a> 
                <a href="https://www.youtube.com/watch?v=T-XafMVKY7E">Demo</a>
            </span>
        </p>
    </div>
    <br>
    <br>
    <br>
    
    <div class="publication">
        <img style=”float: left; padding: 0px 0px 30px 0px;” src="./homepage_files/guard-splat_logo.gif" class="publogo2" width="200 px">
        <p> 
            <strong>
                <a href="https://narcissusex.github.io/GuardSplat/">GuardSplat: Efficient and Robust Watermarking for 3D Gaussian Splatting</a>
            </strong>
            <br>
            Zixuan Chen, <b>Guangcong Wang</b>, Jiahao Zhu, Jianhuang Lai, Xiaohua Xie.
            <br>
            <em>Computer Vision and Pattern Recognition Conference (CVPR), 2025</em>
            <br>
            <span class="links">
                <a href="https://arxiv.org/abs/2411.19895">PDF</a>
                <a href="https://narcissusex.github.io/GuardSplat/">Project Page</a>
                <a href="https://github.com/NarcissusEx/GuardSplat">Code</a> 
                <a href="https://youtu.be/QgejiJE2-5g">Demo</a>
            </span>
        </p>
    </div>
    <br>
    <br>
    <br>   

    
    <div class="publication">
        <img style=”float: left; padding: 0px 0px 30px 0px;” src="./homepage_files/long_video_understanding_logo.png" class="publogo4" width="200 px">
        <p> 
            <strong>
                <a href="https://arxiv.org/abs/2409.18938">From Seconds to Hours: Reviewing MultiModal Large Language Models on Comprehensive Long Video Understanding</a>
            </strong>
            <br>
            Heqing Zou, Tianze Luo, Guiyang Xie, Victor Zhang, Fengmao Lv, <b>Guangcong Wang</b>, Juanyang Chen, Zhuochen Wang, Hansheng Zhang, Huaijian Zhang
            <br>
            <em>Arxiv, 2024</em>
            <br>
            <span class="links">
                <a href="https://arxiv.org/abs/2409.18938">PDF [Survey]</a>
            </span>
        </p>
    </div>
    <br>
    <br>
    <br>
    <div class="publication">
        <img style=”float: left; padding: 0px 0px 30px 0px;” src="./homepage_files/text-based-talkingface.png" class="publogo4" width="200 px">
        <p> 
            <strong>
                <a href="https://arxiv.org/pdf/2407.14841">Text-based Talking Video Editing with Cascaded Conditional Diffusion</a>
            </strong>
            <br>
            Bo Han, Heqing Zou, Haoyang Li, <b>Guangcong Wang</b>, Chng Eng Siong
            <br>
            <em>Arxiv, 2024</em>
            <br>
            <span class="links">
                <a href="https://arxiv.org/pdf/2407.14841">PDF</a>
            </span>
        </p>
    </div>
    <br>
    <br>
    <br>
    
    <div class="publication">
        <img style=”float: left; padding: 0px 0px 30px 0px;” src="./homepage_files/fast-vid2vid++_logo.png" class="publogo2" width="200 px">
        <p> 
            <strong>
                <a href="https://fast-vid2vid.github.io/">Fast-Vid2Vid++: Spatial-Temporal Distillation for Real-Time Video-to-Video Synthesis</a>
            </strong>
            <br>
            Long Zhuo, <b>Guangcong Wang</b>, Shikai Li, Wayne Wu, Ziwei Liu.
            <br>
            <em> IEEE Transactions on Pattern Analysis and Machine Intelligence(TPAMI), 2024</em>
            <br>
            <span class="links">
                <a href="https://arxiv.org/abs/2207.05049">PDF</a>
                <a href="https://fast-vid2vid.github.io/">Project Page</a>
                <a href="https://github.com/fast-vid2vid/fast-vid2vid">Code</a>
                <a href="https://www.youtube.com/watch?v=AhEqjGVuk4A">Demo</a>
            </span>
        </p>
    </div>
    <br>
    <br>
    <br>



    <div class="publication">
        <img style=”float: left; padding: 0px 0px 40px 0px;” src="./homepage_files/mvsgaussian_logo.gif" class="publogo2" width="200 px">
        <p> 
            <strong>
                <a href="https://mvsgaussian.github.io/">MVSGaussian: Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo</a>
            </strong>
            <br>
            Tianqi Liu, <b>Guangcong Wang</b>, Shoukang Hu, Liao Shen, Xinyi Ye, Yuhang Zang, Zhiguo Cao, Wei Li, Ziwei Liu.
            <br>
            <em>European Conference on Computer Vision (ECCV), 2024</em>
            <br>
            <span class="links">
                <a href="https://arxiv.org/abs/2405.12218">PDF</a>
                <a href="https://mvsgaussian.github.io/">Project Page</a>
                <a href="https://github.com/TQTQliu/MVSGaussian">Code</a>
                <a href="https://m.youtube.com/watch?v=yzYVY7apyJE&feature=youtu.be">Demo</a>
            </span>
        </p>
    </div>
    <br>
    <br>
    <br>


        <div class="publication">
            <img src="./homepage_files/perf_logo.gif" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://perf-project.github.io/">PERF: Panoramic Neural Radiance Field from a Single Panorama</a>
                </strong>
		<br>
		<b>Guangcong Wang</b><sup>*</sup>, Peng Wang<sup>*</sup>, Zhaoxi Chen, Wenping Wang, Chen Change Loy, Ziwei Liu
		<br>
                <em> IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2024</em>
		<br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2310.16831">PDF</a>
                    <a href="https://perf-project.github.io/">Project Page</a>
                    <a href="https://github.com/perf-project/PeRF">Code</a>
                    <a href="https://www.youtube.com/watch?v=4wa2h1fjh2U&feature=youtu.be">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
	    
        <div class="publication">
            <img src="./homepage_files/primdiffusion_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://frozenburning.github.io/projects/primdiffusion/">PrimDiffusion: Volumetric Primitives Diffusion for 3D Human Generation</a>
                </strong>
		<br>
		Zhaoxi Chen, Fangzhou Hong, Haiyi Mei, <b>Guangcong Wang</b>, Lei Yang, Ziwei Liu
		<br>
                <em> Neural Information Processing Systems (NeurIPS), 2023</em>
		<br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2312.04559">PDF</a>
                    <a href="https://frozenburning.github.io/projects/primdiffusion/">Project Page</a>
                    <a href="https://github.com/FrozenBurning/PrimDiffusion">Code</a>
                    <a href="https://www.youtube.com/watch?v=zprHGZ7Gm7A&feature=youtu.be">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>

	    
        <div class="publication">
            <img src="./homepage_files/sparsenerf_logo.gif" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://https://sparsenerf.github.io/">SparseNeRF: Distilling Depth Ranking for Few-shot Novel View Synthesis</a>
                </strong>
                <br>
                <b>Guangcong Wang</b>, Zhaoxi Chen, Chen Change Loy, Ziwei Liu.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2023</em>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2303.16196">PDF</a>
                    <a href="https://sparsenerf.github.io/">Project Page</a>
                    <a href="https://github.com/Wanggcong/SparseNeRF">Code</a>
                    <a href="https://www.youtube.com/watch?v=V0yCTakA964&feature=youtu.be">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
	    
	    
        <div class="publication">
            <img src="./homepage_files/scenedreamer_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://scene-dreamer.github.io/">SceneDreamer: Unbounded 3D Scene Generation from 2D Image Collections</a>
                </strong>
                <br>
                Zhaoxi Chen, <b>Guangcong Wang</b>, Ziwei Liu.
                <br>
                <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2023</em>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2302.01330">PDF</a>
                    <a href="https://scene-dreamer.github.io/">Project Page</a>
                    <a href="https://github.com/Scene-Dreamer/SceneDreamer">Code</a>
                    <a href="https://www.youtube.com/watch?v=nEfSKL2_FoA">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
	    
        <div class="publication">
            <img src="./homepage_files/text2light_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://frozenburning.github.io/projects/text2light/">Text2Light: Zero-Shot Text-Driven HDR Panorama Generation</a>
                </strong>
                <br>
                <br>
                Zhaoxi Chen, <b>Guangcong Wang</b>, Ziwei Liu.
                <br>
                <em>ACM Transactions on Graphics (SIGGRAPH Asia), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2209.09898">PDF</a>
                    <a href="https://frozenburning.github.io/projects/text2light/">Project Page</a>
                    <a href="https://github.com/FrozenBurning/Text2Light">Code</a>
                    <a href="https://www.youtube.com/watch?v=XDx6tOHigPE">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
	<br>
         <div class="publication">
            <img src="./homepage_files/stylelight_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://style-light.github.io/">StyleLight: HDR Panorama Generation for Lighting Estimation and Editing</a>
                </strong>
                <br>
                <br>
                <b>Guangcong Wang</b>, Yinuo Yang, Chen Change Loy, Ziwei Liu.
                <br>
                <em>European Conference on Computer Vision (ECCV), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2207.14811">PDF</a>
                    <a href="https://style-light.github.io/">Project Page</a>
                    <a href="https://github.com/Wanggcong/StyleLight">Code</a>
                    <a href="https://www.youtube.com/watch?v=sHeWK1MSPg4">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
	         

        <div class="publication">
            <img src="./homepage_files/fastvid2vid_logo.gif" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://fast-vid2vid.github.io/">Fast-Vid2Vid: Spatial-Temporal Compression for Video-to-Video Synthesis</a>
                </strong>
                <br>
                <br>
                Long Zhuo, <b>Guangcong Wang</b>, Shikai Li, Wayne Wu, Ziwei Liu.
                <br>
                <em>European Conference on Computer Vision (ECCV), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2207.05049">PDF</a>
                    <a href="https://fast-vid2vid.github.io/">Project Page</a>
                    <a href="https://github.com/fast-vid2vid/fast-vid2vid">Code</a>
                    <a href="https://www.youtube.com/watch?v=AhEqjGVuk4A">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br> 
        
        <div class="publication">
            <img src="./homepage_files/triplet_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://github.com/wanggrun/triplet">Solving Inefficiency of Self-supervised Representation Learning</a>
                </strong>
                <br>
                <br>
                Guangrun Wang, Keze Wang, <b>Guangcong Wang</b>, Philip Torr, Liang Lin.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_Solving_Inefficiency_of_Self-Supervised_Representation_Learning_ICCV_2021_paper.pdf">PDF</a>
                    <a href="https://github.com/wanggrun/triplet">Code</a>
                    <a href="https://arxiv.org/abs/2104.08760">arXiv</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br> 

        <div class="publication">
            <img src="./homepage_files/h2h_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://ieeexplore.ieee.org/document/9470916">Homogeneous-to-Heterogeneous:  Unsupervised Learning for  RGB-Infrared Person Re-Identification</a>
                </strong>
                <br>
                <br>
                Wenqi Liang, <b>Guangcong Wang</b>, Jianhuang Lai, Xiaohua Xie.
                <br>
                <em>IEEE Transactions on Image Processing (TIP), 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://ieeexplore.ieee.org/document/9470916">PDF</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br> 

        <div class="publication">
            <img src="./homepage_files/Joint Learning_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://ieeexplore.ieee.org/document/9408408">Joint Learning of Neural Transfer and Architecture Adaptation for Image Recognition</a>
                </strong>
                <br>
                <br>
                Guangrun Wang, Liang Lin, Rongcong Chen, <b>Guangcong Wang</b>, Jiqi Zhang.
                <br>
                <em>IEEE Transactions on Neural Networks and Learning Systems (TNNLS), 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://ieeexplore.ieee.org/document/9408408">PDF</a> 
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>         

        <div class="publication">
            <img src="./homepage_files/Confidence_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2105.06714">Confidence-Guided Adaptive Gate and Dual Differential Enhancement for Video Salient Object Detection</a>
                </strong>
                <br>
                <br>
                Peijia Chen, Jianhuang Lai, <b>Guangcong Wang</b>, Huajun Zhou.
                <br>
                <em>IEEE International Conference on Multimedia and Expo (ICME), 2021 (oral)</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2105.06714">PDF</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br> 

        <div class="publication">
            <img src="./homepage_files/Smoothing_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Smoothing_Adversarial_Domain_Attack_and_P-Memory_Reconsolidation_for_Cross-Domain_Person_CVPR_2020_paper.pdf">Smoothing Adversarial Domain Attack and p-Memory Reconsolidation for Cross-Domain Person Re-Identification</a>
                </strong>
                <br>
                <br>
                <b>Guangcong Wang</b>, Jianhuang Lai, Wenqi Liang, Guangrun Wang.
                <br>
                <em>Computer Vision and Pattern Recognition Conference (CVPR) , 2020</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Smoothing_Adversarial_Domain_Attack_and_P-Memory_Reconsolidation_for_Cross-Domain_Person_CVPR_2020_paper.pdf">PDF</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>         
    
        <div class="publication">
            <img src="./homepage_files/weaklyreid_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://github.com/wanggrun/SYSU-30k">Weakly Supervised Person Re-identification: Cost-effective Learning with A New Benchmark</a>
                </strong>
                <br>
                <br>
                Guangrun Wang, <b>Guangcong Wang</b>, Xujie Zhang, Jianhuang Lai, Liang Lin.
                <br>
                <em>IEEE Transactions on Neural Networks and Learning Systems (TNNLS), 2020</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/1904.03845">PDF</a>
                    <a href="https://github.com/wanggrun/SYSU-30k">Dataset, Code, Pretrained model</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br> 


        <div class="publication">
            <img src="./homepage_files/treeconv_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://www.kdd.org/kdd2020/accepted-papers/view/grammatically-recognizing-images-with-tree-convolution">Grammatically Recognizing Images with Tree Convolution</a>
                </strong>
                <br>
                <br>
                Guangrun Wang, <b>Guangcong Wang</b>, Keze Wang, Xiaodan Liang, Liang Lin.
                <br>
                <em>ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (KDD), 2020</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://www.kdd.org/kdd2020/accepted-papers/view/grammatically-recognizing-images-with-tree-convolution">PDF</a>
                    <a href="https://github.com/wanggrun/TreeConv/stargazers">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>   

        <div class="publication">
            <img src="./homepage_files/streid_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://github.com/Wanggcong/Spatial-Temporal-Re-identification">Spatial-Temporal Person Re-identification</a>
                </strong>
                <br>
                <br>
                <b>Guangcong Wang</b>, Jianhuang Lai, Peigen Huang and Xiaohua Xie.
                <br>
                <em>The Association for the Advancement of Artificial Intelligence (AAAI), 2019</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://wvvw.aaai.org/ojs/index.php/AAAI/article/view/4921">PDF</a>
                    <a href="https://github.com/Wanggcong/Spatial-Temporal-Re-identification">Code</a>
                    <a href="https://arxiv.org/abs/1812.03282">arXiv</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br> 

      

        <div class="publication">
            <img src="./homepage_files/m2m_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/pdf/1811.03768.pdf">M2M-GAN: Many-to-Many Generative Adversarial Transfer Learning for Person Re-Identification</a>
                </strong>
                <br>
                <br>
                Wenqi Liang, <b>Guangcong Wang</b>, Jianhuang Lai.
                <br>
                <em>ACTA AUTOMATICA SINICA, 2019</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/pdf/1811.03768.pdf">arXiv</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br> 
        <div class="publication">
            <img src="./homepage_files/Ocluded_ReID_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/pdf/1804.02792.pdf">Ocluded Person Re-identification</a>
                </strong>
                <br>
                <br>
                Jiaxuan Zhuo, Zeyu Chen, Jianhuang Lai, <b>Guangcong Wang</b>.
                <br>
                <em>IEEE International Conference on Multimedia and Expo (ICME), 2021 (oral)</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/pdf/1804.02792.pdf">PDF</a>
		    <a href="https://github.com/tinajia2012/ICME2018_Occluded-Person-Reidentification_datasets">Dataset</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br> 	    
        <div class="publication">
            <img src="./homepage_files/P2SNet_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://ieeexplore.ieee.org/document/8025424">P2SNet: Can an Image Match a Video for Person Re-identification in an End-to-end Way</a>
                </strong>
                <br>
                <b>Guangcong Wang</b>, Jianhuang Lai, Xiaohua Xie.
                <br>
                <em>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2018</em>
                <br>
                <span class="links">
                    <a href="https://ieeexplore.ieee.org/document/8025424">PDF</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>         

        <div class="publication">
            <img src="./homepage_files/DGL_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Wang_Deep_Growing_Learning_ICCV_2017_paper.pdf">Deep Growing Learning</a>
                </strong>
                <br>
                <br>
                <b>Guangcong Wang</b>, Xiaohua Xie, Jianhuang Lai, Jiaxuan Zhuo.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2017</em>
                <br>
                <br>
                <span class="links">
                    <a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Wang_Deep_Growing_Learning_ICCV_2017_paper.pdf">PDF</a>
                    <a href="https://github.com/Wanggcong/Deep-growing-learning">Code</a>
                    
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>  
       </div>
</body></html>
